{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapper and Reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapper reads the keyboard log file and extract the lines for Team Fortress 2 key bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting keyLogMapperV2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile keyLogMapperV2.py\n",
    "#!/opt/bitnami/python/bin/python\n",
    "# -*-coding:utf-8 -*\n",
    "import sys\n",
    "import string\n",
    "\n",
    "# The 49 default key bindings for team fortress 2\n",
    "keyBindings = [\"w\",\"a\",\"s\",\"d\",\"Key.space\",\"Key.ctrl_l\",\"'\",\"/\",\"Key.up\",\"Key.down\",\n",
    "                \"v\",\"y\",\"u\",\"z\",\"x\",\"c\",\",\",\".\",\"m\",\"n\",\"Key.f2\",\"Key.f3\",\"l\",\"g\",\n",
    "               \"h\",\"i\",\"f\",\"b\",\"-\",\"r\",\"q\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\n",
    "               \"t\",\"Key.tab\",\"Key.f5\",\"Key.f6\",\"Key.f7\",\"`\",\"j\",\"k\"]\n",
    "\n",
    "for line in sys.stdin: # reads from stdin\n",
    "    #reading the keyboard log file, extract the wanted data\n",
    "    line = line.replace(\"'\", \"\")\n",
    "    line = line.strip()\n",
    "    words = line.split(\",\")\n",
    "    keyName = words[1]\n",
    "    if keyName in keyBindings: #Check whether this line belongs to the 49 key bindings\n",
    "        time = float(words[0])\n",
    "        action = words[2]\n",
    "        output = keyName+\",\"+ str(time) +\",\"+ action\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reducer reads the outputs of mapper, and the outputs of mapper were grouped and sorted by hadoop streaming. The reducer will calculte how many times each key was pressed and the avergae press duration for keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting keyLogReducerV2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile keyLogReducerV2.py\n",
    "#!/opt/bitnami/python/bin/python\n",
    "# -*-coding:utf-8 -*\n",
    "\n",
    "import sys\n",
    "presses = {} #A dictionary used to track the valid presses of keys\n",
    "releases = {} #A dictionary used to track the valid releases of keys\n",
    "duration = {} #A dictionary used to track the average pressed duration of each key\n",
    "lastKey = None #A flag to monitor whether the reducer is reading a new key's record\n",
    "lastAction = None #A a flag used to identify continuous repeated presses of a key\n",
    "\n",
    "#Recording freqencies, pressed times and released times for keys\n",
    "for line in sys.stdin:\n",
    "    #reading the sorted output of mapper, extract the wanted data.\n",
    "    line = line.strip()\n",
    "    words = line.split(\"\\t\")\n",
    "    key = words[0].split(\",\")\n",
    "    keyName = key[0]\n",
    "    time = float(key[1])\n",
    "    action = words[1]\n",
    "    if lastKey is None:\n",
    "        lastKey = keyName\n",
    "    if lastKey == keyName:\n",
    "        if action == \"pressed\":\n",
    "            if lastAction==\"pressed\":\n",
    "                continue\n",
    "            if keyName in presses:\n",
    "                presses[keyName].append(time)\n",
    "            else:\n",
    "                presses[keyName] = [time]\n",
    "            lastAction = \"pressed\"\n",
    "        else:\n",
    "            lastAction = None\n",
    "            if keyName in releases:\n",
    "                releases[keyName].append(time)\n",
    "            else:\n",
    "                releases[keyName] = [time]\n",
    "        if keyName not in duration:\n",
    "            duration[keyName] = 0\n",
    "    else:\n",
    "        lastAction=None\n",
    "        presses[lastKey] = sorted(presses[lastKey])\n",
    "        releases[lastKey] = sorted(releases[lastKey])\n",
    "        for x in range(0, len(presses[lastKey])) :\n",
    "            duration[lastKey] += (releases[lastKey][x]-presses[lastKey][x])\n",
    "        duration[lastKey] = duration[lastKey]/len(presses[lastKey])\n",
    "        duration[lastKey] = \"{:.5f}\".format(duration[lastKey])\n",
    "        output = lastKey +\" \"+ str(duration[lastKey])+\" \"+str(len(presses[lastKey]))\n",
    "        print(output)\n",
    "        lastKey = keyName\n",
    "        if action == \"pressed\":\n",
    "            lastAction = \"pressed\"\n",
    "            if keyName in presses:\n",
    "                presses[keyName].append(time)\n",
    "            else:\n",
    "                presses[keyName] = [time]\n",
    "        else:\n",
    "            lastAction = None\n",
    "            if keyName in releases:\n",
    "                releases[keyName].append(time)\n",
    "            else:\n",
    "                releases[keyName] = [time]\n",
    "        if keyName not in duration:\n",
    "            duration[keyName] = 0\n",
    "\n",
    "\n",
    "if lastKey is not None:\n",
    "    presses[lastKey] = sorted(presses[lastKey])\n",
    "    releases[lastKey] = sorted(releases[lastKey])\n",
    "    for x in range(0, len(presses[lastKey])) :\n",
    "        duration[lastKey] += (releases[lastKey][x]-presses[lastKey][x])\n",
    "    duration[lastKey] = duration[lastKey]/len(presses[lastKey])\n",
    "    duration[lastKey] = \"{:.5f}\".format(duration[lastKey])\n",
    "    output = lastKey +\" \"+ str(duration[lastKey])+\" \"+str(len(presses[lastKey]))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-09 23:31:21,946 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put Hengjun /inputs/Capstone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /outputs/Capstone/Jonathan\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -r /outputs/Capstone/Jonathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using hadoop streaming to run the MapReduce job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in hadoop streaming, here's the official documentation: https://hadoop.apache.org/docs/r3.2.1/hadoop-streaming/HadoopStreaming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 04:44:18,427 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/training/Capstone/keyLogMapperV2.py, /training/Capstone/keyLogReducerV2.py, /tmp/hadoop-unjar5839946848324483523/] [] /tmp/streamjob6592926802713631732.jar tmpDir=null\n",
      "2021-11-10 04:44:19,934 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.4:8032\n",
      "2021-11-10 04:44:20,248 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2021-11-10 04:44:20,322 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.18.0.4:8032\n",
      "2021-11-10 04:44:20,323 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.18.0.3:10200\n",
      "2021-11-10 04:44:20,606 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1636493424467_0086\n",
      "2021-11-10 04:44:20,786 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:20,950 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:20,971 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:21,079 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2021-11-10 04:44:21,134 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:21,166 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:21,179 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2021-11-10 04:44:21,356 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-11-10 04:44:21,378 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1636493424467_0086\n",
      "2021-11-10 04:44:21,379 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2021-11-10 04:44:21,631 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-11-10 04:44:21,631 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2021-11-10 04:44:21,955 INFO impl.YarnClientImpl: Submitted application application_1636493424467_0086\n",
      "2021-11-10 04:44:22,003 INFO mapreduce.Job: The url to track the job: http://resourcemanager:8088/proxy/application_1636493424467_0086/\n",
      "2021-11-10 04:44:22,005 INFO mapreduce.Job: Running job: job_1636493424467_0086\n",
      "2021-11-10 04:44:30,154 INFO mapreduce.Job: Job job_1636493424467_0086 running in uber mode : false\n",
      "2021-11-10 04:44:30,157 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2021-11-10 04:44:37,289 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "2021-11-10 04:44:38,299 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2021-11-10 04:44:43,344 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2021-11-10 04:44:43,360 INFO mapreduce.Job: Job job_1636493424467_0086 completed successfully\n",
      "2021-11-10 04:44:43,527 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=24587\n",
      "\t\tFILE: Number of bytes written=750692\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=125872\n",
      "\t\tHDFS: Number of bytes written=192\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31588\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=25480\n",
      "\t\tTotal time spent by all map tasks (ms)=7897\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3185\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7897\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3185\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=32346112\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=26091520\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5415\n",
      "\t\tMap output records=5353\n",
      "\t\tMap output bytes=103427\n",
      "\t\tMap output materialized bytes=24703\n",
      "\t\tInput split bytes=262\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5353\n",
      "\t\tReduce shuffle bytes=24703\n",
      "\t\tReduce input records=5353\n",
      "\t\tReduce output records=13\n",
      "\t\tSpilled Records=10706\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=452\n",
      "\t\tCPU time spent (ms)=3890\n",
      "\t\tPhysical memory (bytes) snapshot=941555712\n",
      "\t\tVirtual memory (bytes) snapshot=18470518784\n",
      "\t\tTotal committed heap usage (bytes)=873988096\n",
      "\t\tPeak Map Physical memory (bytes)=453038080\n",
      "\t\tPeak Map Virtual memory (bytes)=5042438144\n",
      "\t\tPeak Reduce Physical memory (bytes)=184705024\n",
      "\t\tPeak Reduce Virtual memory (bytes)=8389484544\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=125610\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=192\n",
      "2021-11-10 04:44:43,528 INFO streaming.StreamJob: Output directory: /outputs/Capstone/Jonathan\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \\\n",
    "    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\\n",
    "    -D stream.map.output.field.separator=, \\\n",
    "    -D stream.num.map.output.key.fields=2 \\\n",
    "    -D mapreduce.map.output.key.field.separator=, \\\n",
    "    -D mapreduce.partition.keycomparator.options='-k1,1 -k2,2n' \\\n",
    "    -D mapreduce.job.reduces=1\\\n",
    "    -file $PWD/keyLogMapperV2.py\\\n",
    "    -file $PWD/keyLogReducerV2.py\\\n",
    "    -mapper keyLogMapperV2.py \\\n",
    "    -reducer keyLogReducerV2.py \\\n",
    "    -input /inputs/Capstone/Jonathan \\\n",
    "    -output /outputs/Capstone/Jonathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The outputs in the format of (Key, Avg_Time_Pressed, Times_Pressed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 04:44:47,247 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "1 0.15647 3\t\n",
      "2 0.14135 12\t\n",
      "3 0.10398 5\t\n",
      "4 0.12002 4\t\n",
      "5 0.11190 1\t\n",
      "7 0.10960 1\t\n",
      "Key.f2 0.14490 2\t\n",
      "Key.space 0.31643 21\t\n",
      "a 0.46021 408\t\n",
      "d 0.41633 347\t\n",
      "q 0.15900 1\t\n",
      "s 0.60834 111\t\n",
      "w 2.38953 254\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /outputs/Capstone/Jonathan/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the output file from Hadoop Distributed File System to local(virtual machine on a Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 04:49:56,875 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyToLocal /outputs/Capstone/Jonathan/* /training/Capstone/Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS  part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!ls /training/Capstone/Outputs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
